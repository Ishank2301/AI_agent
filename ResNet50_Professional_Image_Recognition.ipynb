{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Image Classification using Pretrained ResNet50\n",
        "\n",
        "This project demonstrates image classification using a pretrained ResNet50 model (ImageNet weights).\n",
        "\n",
        "### Features:\n",
        "- Single Image Prediction\n",
        "- Top-5 Confidence Visualization\n",
        "- Grad-CAM Explainability\n",
        "- Batch Image Prediction\n",
        "- Feature Extraction (Transfer Learning Ready)\n",
        "\n",
        "**Author:** Ishank Mishra"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input, decode_predictions\n",
        "from tensorflow.keras.preprocessing import image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Load Model\n",
        "def load_model():\n",
        "    model = ResNet50(weights='imagenet')\n",
        "    print('ResNet50 Loaded Successfully')\n",
        "    return model\n",
        "\n",
        "model = load_model()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Image Preprocessing\n",
        "def preprocess_image(img_path):\n",
        "    img = image.load_img(img_path, target_size=(224, 224))\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    img_array = preprocess_input(img_array)\n",
        "    return img, img_array"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Prediction Function\n",
        "def predict_image(model, img_array):\n",
        "    preds = model.predict(img_array)\n",
        "    decoded = decode_predictions(preds, top=5)[0]\n",
        "    print('\\nTop 5 Predictions:\\n')\n",
        "    for i in decoded:\n",
        "        print(f\"{i[1]} : {round(i[2]*100,2)}%\")\n",
        "    return decoded, preds"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Plot Confidence\n",
        "def plot_top_predictions(decoded_preds):\n",
        "    labels = [i[1] for i in decoded_preds]\n",
        "    scores = [i[2] for i in decoded_preds]\n",
        "    plt.figure(figsize=(8,5))\n",
        "    plt.barh(labels, scores)\n",
        "    plt.xlabel('Confidence')\n",
        "    plt.title('Top 5 Prediction Confidence')\n",
        "    plt.gca().invert_yaxis()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Grad-CAM\n",
        "def make_gradcam_heatmap(img_array, model, last_conv_layer_name='conv5_block3_out'):\n",
        "    grad_model = tf.keras.models.Model(\n",
        "        [model.inputs],\n",
        "        [model.get_layer(last_conv_layer_name).output, model.output]\n",
        "    )\n",
        "    with tf.GradientTape() as tape:\n",
        "        conv_outputs, predictions = grad_model(img_array)\n",
        "        loss = predictions[:, np.argmax(predictions[0])]\n",
        "    grads = tape.gradient(loss, conv_outputs)\n",
        "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
        "    conv_outputs = conv_outputs[0]\n",
        "    heatmap = conv_outputs @ pooled_grads[..., tf.newaxis]\n",
        "    heatmap = tf.squeeze(heatmap)\n",
        "    heatmap = np.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
        "    return heatmap.numpy()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Overlay Grad-CAM\n",
        "def overlay_heatmap(img_path, heatmap, alpha=0.4):\n",
        "    img = cv2.imread(img_path)\n",
        "    img = cv2.resize(img, (224,224))\n",
        "    heatmap = cv2.resize(heatmap, (224,224))\n",
        "    heatmap = np.uint8(255 * heatmap)\n",
        "    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
        "    superimposed = cv2.addWeighted(img, 1-alpha, heatmap, alpha, 0)\n",
        "    plt.imshow(cv2.cvtColor(superimposed, cv2.COLOR_BGR2RGB))\n",
        "    plt.axis('off')\n",
        "    plt.title('Grad-CAM Visualization')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Batch Prediction\n",
        "def batch_predict(folder_path, model):\n",
        "    print('\\nBatch Prediction Results:\\n')\n",
        "    for file in os.listdir(folder_path):\n",
        "        img_path = os.path.join(folder_path, file)\n",
        "        try:\n",
        "            _, img_array = preprocess_image(img_path)\n",
        "            preds = model.predict(img_array)\n",
        "            decoded = decode_predictions(preds, top=1)[0][0]\n",
        "            print(f\"{file} \u2192 {decoded[1]} ({round(decoded[2]*100,2)}%)\")\n",
        "        except:\n",
        "            continue"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Feature Extraction\n",
        "feature_model = ResNet50(weights='imagenet', include_top=False)\n",
        "\n",
        "def extract_features(img_array):\n",
        "    features = feature_model.predict(img_array)\n",
        "    print('Feature shape:', features.shape)\n",
        "    return features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusion\n",
        "\n",
        "This project demonstrates:\n",
        "- Image Classification using pretrained ResNet50\n",
        "- Confidence Visualization\n",
        "- Explainable AI (Grad-CAM)\n",
        "- Batch Inference\n",
        "- Feature Extraction for Transfer Learning\n",
        "\n",
        "Future Improvements:\n",
        "- Fine-tuning on custom dataset\n",
        "- Deploy using Streamlit or Flask\n",
        "- Build Image Similarity Search System"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}